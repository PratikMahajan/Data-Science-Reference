{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB playing with Tags in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ConnectionFailure\n",
    "from bson import json_util, ObjectId\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "import requests\n",
    "import json, os\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "import pprint\n",
    "from datetime import datetime\n",
    "random.seed(datetime.now())\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Make plots larger\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db=client.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tweets']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.collection_names(include_system_collections=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytics tweets dropped\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = db.tweets.drop()\n",
    "    print (\"analytics tweets dropped\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_json(j):\n",
    "    p=os.path.join(\"data/\", j)\n",
    "    print (p)\n",
    "    with open(p, 'rU') as f:\n",
    "      data = [json.loads(row) for row in f]\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/db_tweets.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'contributors': None,\n",
       " 'coordinates': None,\n",
       " 'created_at': 'Sun Mar 15 21:41:22 +0000 2015',\n",
       " 'entities': {'hashtags': [{'indices': [128, 136], 'text': 'Bigdata'},\n",
       "   {'indices': [137, 140], 'text': 'IoT'},\n",
       "   {'indices': [139, 140], 'text': 'CIO'}],\n",
       "  'symbols': [],\n",
       "  'trends': [],\n",
       "  'urls': [{'display_url': 'bit.ly/1jvQFcK',\n",
       "    'expanded_url': 'http://bit.ly/1jvQFcK',\n",
       "    'indices': [105, 127],\n",
       "    'url': 'http://t.co/gLf50KtZKx'}],\n",
       "  'user_mentions': [{'id': 474651213,\n",
       "    'id_str': '474651213',\n",
       "    'indices': [3, 15],\n",
       "    'name': 'Marc Wilczek',\n",
       "    'screen_name': 'MarcWilczek'}]},\n",
       " 'favorite_count': 0,\n",
       " 'favorited': False,\n",
       " 'filter_level': 'low',\n",
       " 'geo': None,\n",
       " 'id': 577223085054558208,\n",
       " 'id_str': '577223085054558208',\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'lang': 'en',\n",
       " 'place': None,\n",
       " 'possibly_sensitive': False,\n",
       " 'retweet_count': 0,\n",
       " 'retweeted': False,\n",
       " 'retweeted_status': {'contributors': None,\n",
       "  'coordinates': None,\n",
       "  'created_at': 'Sun Mar 15 21:20:26 +0000 2015',\n",
       "  'entities': {'hashtags': [{'indices': [111, 119], 'text': 'Bigdata'},\n",
       "    {'indices': [120, 124], 'text': 'IoT'},\n",
       "    {'indices': [125, 129], 'text': 'CIO'}],\n",
       "   'symbols': [],\n",
       "   'trends': [],\n",
       "   'urls': [{'display_url': 'bit.ly/1jvQFcK',\n",
       "     'expanded_url': 'http://bit.ly/1jvQFcK',\n",
       "     'indices': [88, 110],\n",
       "     'url': 'http://t.co/gLf50KtZKx'}],\n",
       "   'user_mentions': []},\n",
       "  'favorite_count': 0,\n",
       "  'favorited': False,\n",
       "  'filter_level': 'low',\n",
       "  'geo': None,\n",
       "  'id': 577217818753548288,\n",
       "  'id_str': '577217818753548288',\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'lang': 'en',\n",
       "  'place': None,\n",
       "  'possibly_sensitive': False,\n",
       "  'retweet_count': 1,\n",
       "  'retweeted': False,\n",
       "  'source': '<a href=\"http://twuffer.com\" rel=\"nofollow\">Twuffer</a>',\n",
       "  'text': 'In 2014, the digital universe equaled 1.7 megabytes a minute for every person on Earth: http://t.co/gLf50KtZKx #Bigdata #IoT #CIO',\n",
       "  'truncated': False,\n",
       "  'user': {'contributors_enabled': False,\n",
       "   'created_at': 'Thu Jan 26 06:24:30 +0000 2012',\n",
       "   'default_profile': False,\n",
       "   'default_profile_image': False,\n",
       "   'description': 'Passionate about Tech, Innovation, Strategy and Change. VP Portfolio, Innovation, Architecture @ T-Systems—Deutsche Telekom. Views are my own',\n",
       "   'favourites_count': 192,\n",
       "   'follow_request_sent': None,\n",
       "   'followers_count': 8726,\n",
       "   'following': None,\n",
       "   'friends_count': 599,\n",
       "   'geo_enabled': True,\n",
       "   'id': 474651213,\n",
       "   'id_str': '474651213',\n",
       "   'is_translator': False,\n",
       "   'lang': 'de',\n",
       "   'listed_count': 158,\n",
       "   'location': 'Frankfurt am Main, Germany',\n",
       "   'name': 'Marc Wilczek',\n",
       "   'notifications': None,\n",
       "   'profile_background_color': '030302',\n",
       "   'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/450722427484385281/kI1yHyhI.jpeg',\n",
       "   'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/450722427484385281/kI1yHyhI.jpeg',\n",
       "   'profile_background_tile': False,\n",
       "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/474651213/1396102695',\n",
       "   'profile_image_url': 'http://pbs.twimg.com/profile_images/378800000687547211/66fbdde017be98bcb15ce759766e86cd_normal.jpeg',\n",
       "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/378800000687547211/66fbdde017be98bcb15ce759766e86cd_normal.jpeg',\n",
       "   'profile_link_color': '786A55',\n",
       "   'profile_sidebar_border_color': 'FFFFFF',\n",
       "   'profile_sidebar_fill_color': '12291F',\n",
       "   'profile_text_color': '547B61',\n",
       "   'profile_use_background_image': False,\n",
       "   'protected': False,\n",
       "   'screen_name': 'MarcWilczek',\n",
       "   'statuses_count': 8725,\n",
       "   'time_zone': None,\n",
       "   'url': 'http://www.marcwilczek.com',\n",
       "   'utc_offset': None,\n",
       "   'verified': False}},\n",
       " 'source': '<a href=\"http://www.simbasystems.com\" rel=\"nofollow\">NoSQLDigest</a>',\n",
       " 'text': 'RT @MarcWilczek: In 2014, the digital universe equaled 1.7 megabytes a minute for every person on Earth: http://t.co/gLf50KtZKx #Bigdata #I…',\n",
       " 'timestamp_ms': '1426455682420',\n",
       " 'truncated': False,\n",
       " 'user': {'contributors_enabled': False,\n",
       "  'created_at': 'Sun Aug 03 17:07:24 +0000 2014',\n",
       "  'default_profile': True,\n",
       "  'default_profile_image': False,\n",
       "  'description': 'NoSQL Digest of tweets.',\n",
       "  'favourites_count': 72,\n",
       "  'follow_request_sent': None,\n",
       "  'followers_count': 5418,\n",
       "  'following': None,\n",
       "  'friends_count': 12,\n",
       "  'geo_enabled': False,\n",
       "  'id': 2704548373,\n",
       "  'id_str': '2704548373',\n",
       "  'is_translator': False,\n",
       "  'lang': 'en',\n",
       "  'listed_count': 1799,\n",
       "  'location': '',\n",
       "  'name': 'NoSQL',\n",
       "  'notifications': None,\n",
       "  'profile_background_color': 'C0DEED',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/499257180009529344/CSWhr7LZ_normal.jpeg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/499257180009529344/CSWhr7LZ_normal.jpeg',\n",
       "  'profile_link_color': '0084B4',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'protected': False,\n",
       "  'screen_name': 'NoSQLDigest',\n",
       "  'statuses_count': 362920,\n",
       "  'time_zone': None,\n",
       "  'url': None,\n",
       "  'utc_offset': None,\n",
       "  'verified': False}}"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_j=load_json('db_tweets.json')\n",
    "tweets_j[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @MarcWilczek: In 2014, the digital universe equaled 1.7 megabytes a minute for every person on Earth: http://t.co/gLf50KtZKx #Bigdata #I…\n"
     ]
    }
   ],
   "source": [
    "print(tweets_j[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_json(tid,text,created,favorite_count,retweet_count,urls,tags):\n",
    "    j={\n",
    "    \"tweet_id\" : tid,\n",
    "    \"text\" : text,\n",
    "    \"favorite_count\" : favorite_count,  \n",
    "    \"retweet_count\" : retweet_count,\n",
    "    \"urls\" : urls, \n",
    "    \"tags\" : tags,         \n",
    "    \"created_at\" : created}\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-03-15 21:41\n",
      "2011-03-29 08:11\n"
     ]
    }
   ],
   "source": [
    "# Twitter dates are of the form Sun Mar 15 21:41:54 +0000 2015\n",
    "datestrings=['Sun Mar 15 21:41:54 +0000 2015','Tue Mar 29 08:11:25 +0000 2011']\n",
    "from datetime import timedelta\n",
    "from email.utils import parsedate_tz\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def to_datetime(datestring):\n",
    "    time_tuple = parsedate_tz(datestring.strip())\n",
    "    dt = datetime(*time_tuple[:6])\n",
    "    return dt - timedelta(seconds=time_tuple[-1])\n",
    "\n",
    "ts=to_datetime(datestrings[0])\n",
    "print (ts.strftime(\"%Y-%m-%d %H:%M\"))\n",
    "ts=to_datetime(datestrings[1])\n",
    "print (ts.strftime(\"%Y-%m-%d %H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bigdata': 0, 'big data': 0, 'algorithm': 0, 'AI': 0, 'MongoDB': 0, 'SQL': 0, 'artificial intelligence': 0, 'machine learning': 0}\n"
     ]
    }
   ],
   "source": [
    "hashtags={}\n",
    "starter_tags=['Bigdata','big data','algorithm','big data','AI','MongoDB','SQL','artificial intelligence','machine learning']\n",
    "for tag in starter_tags:\n",
    "    hashtags[tag]=0\n",
    "urls={}\n",
    "tags={}\n",
    "print(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @TheHesterView Tutorials on big data, big data, AI, MongoDB, SQL, artificial intelligence, machine learning. hackathons, crowdsourcing, #bigdata http://t.co/6HWjCv3BL5 Lets join \n"
     ]
    }
   ],
   "source": [
    "sample_tweet_text=\"RT @TheHesterView Tutorials on big data, big data, AI, MongoDB, SQL, artificial intelligence, machine learning. hackathons, crowdsourcing, #bigdata http://t.co/6HWjCv3BL5 Lets join \"\n",
    "print (sample_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', 'TheHesterView', 'Tutorials', 'on', 'big', 'data', 'big', 'data', 'AI', 'MongoDB', 'SQL', 'artificial', 'intelligence', 'machine', 'learning', 'hackathons', 'crowdsourcing', '#bigdata', 'http://t.co/6HWjCv3BL5', 'Lets', 'join', '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def tokenize(txt):  \n",
    "  txt=re.sub(r'\\n', ' ',txt)\n",
    "  txt=re.compile(r'[\\.][ ]+').sub(' ',txt)      \n",
    "  txt=re.compile(r'[\\,][ ]+').sub(' ',txt)    \n",
    "  txt=re.compile(r'[_+;=!@$%^&\\*\\\"\\?]').sub(' ',txt)  \n",
    "  splitter=re.compile(r'[ ]+')\n",
    "  # Split the words by non-alpha characters\n",
    "  words=splitter.split(txt)\n",
    "  return words\n",
    "print (tokenize(sample_tweet_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http\n"
     ]
    }
   ],
   "source": [
    "s='http://t.co/6HWjCv3BL5'\n",
    "print (s[0:4].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn'])\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words_list = list(stopwords.words('english'))\n",
    "stop_words={}\n",
    "for tag in stop_words_list:\n",
    "    stop_words[tag]=0\n",
    "print (stop_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_urls_tags(url_list,urls,hashtag_list,hashtags,tag_list,tags):  \n",
    "  for url in url_list:\n",
    "      if url in urls:\n",
    "        urls[url]=urls[url]+1\n",
    "      else:\n",
    "        urls[url]=1\t \n",
    "  for tag in tag_list:\n",
    "      if tag in tags:\n",
    "        tags[tag]=tags[tag]+1\n",
    "      else:\n",
    "        tags[tag]=1\t \n",
    "  for hashtag in hashtag_list:\n",
    "      if hashtag in hashtags:\n",
    "        hashtags[hashtag]=hashtags[hashtag]+1\n",
    "      else:\n",
    "        hashtags[hashtag]=1        \n",
    "  return urls,hashtags,tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['big data', 'AI', 'MongoDB', 'SQL', 'artificial intelligence', 'machine learning', '#bigdata'], ['http://t.co/6HWjCv3BL5'], ['RT', 'TheHesterView Tutorials', 'TheHesterView', 'Tutorials on', 'Tutorials', 'big data', 'big', 'data big', 'data', 'data AI', 'AI MongoDB', 'AI', 'MongoDB SQL', 'MongoDB', 'SQL artificial', 'SQL', 'artificial intelligence', 'artificial', 'intelligence machine', 'intelligence', 'machine learning', 'machine', 'learning hackathons', 'learning', 'hackathons crowdsourcing', 'hackathons', 'crowdsourcing #bigdata', 'crowdsourcing', '#bigdata http://t.co/6HWjCv3BL5', '#bigdata', 'http://t.co/6HWjCv3BL5 Lets', 'http://t.co/6HWjCv3BL5', 'Lets join', 'Lets', 'join ', 'join'])\n"
     ]
    }
   ],
   "source": [
    "def extract_tags_urls(dct,words,stop):\n",
    "  i=0\n",
    "  tags={} \n",
    "  tokens={}     \n",
    "  urls={}     \n",
    "  size=len(words)   \n",
    "  while i < size:\n",
    "    ngram = words[i]\n",
    "    i=i+1\n",
    "    if len(ngram) < 1: continue\n",
    "    if len(ngram) > 4:        \n",
    "      if ngram[0:4].lower()=='http':\n",
    "        if ngram in urls:\n",
    "          urls[ngram]=urls[ngram]+1\n",
    "        else:\n",
    "          urls[ngram]=1\t \n",
    "    if ngram[0]=='#':\n",
    "  #    ngram=re.sub(r'\\#', '',ngram)     if you want to remove the # \n",
    "      tags[ngram]=1 \n",
    "    if ngram.lower() not in stop:    \n",
    "        tokens[ngram]=1\t          \n",
    "    if ngram in dct:\n",
    "      tags[ngram]=1\n",
    "    if i < (size-1):\n",
    "      ngram = words[i] + ' ' + words[i+1]\n",
    "      if words[i].lower() not in stop:    \n",
    "        tokens[ngram]=1\t        \n",
    "      if ngram in dct:\n",
    "        tags[ngram]=1\n",
    "    if i < (size-2):\n",
    "      ngram = words[i] + ' ' + words[i+1] + ' ' + words[i+2]           \n",
    "      if ngram in dct:\n",
    "        tags[ngram]=1\n",
    "  return list(tags.keys()),list(urls.keys()),list(tokens.keys())\n",
    "print (extract_tags_urls(hashtags,(tokenize(sample_tweet_text)),stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 tweets inserted.\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for tweet in tweets_j:\n",
    "    ts=datetime.now()\n",
    "    try:\n",
    "        ts=to_datetime(tweet['created_at'])\n",
    "    except:\n",
    "        continue  \n",
    "    favorite_count=0\n",
    "    try:\n",
    "        favorite_count=int(tweet['favorite_count'])\n",
    "    except:\n",
    "        pass \n",
    "    retweet_count=0\n",
    "    try:\n",
    "        retweet_count=int(tweet['retweet_count'])\n",
    "    except:\n",
    "        pass  \n",
    "    tweet_tags,tweet_urls,tweet_ngrams=extract_tags_urls(hashtags,(tokenize(tweet['text'])),stop_words)\n",
    "    urls,hashtags,tags=update_urls_tags(tweet_urls,urls,tweet_tags,hashtags,tweet_ngrams,tags)\n",
    "    try:\n",
    "        j=tweet_json(tweet['id'],tweet['text'],ts,favorite_count,retweet_count,tweet_urls,tweet_tags)\n",
    "        result = db.tweets.insert_one(j)\n",
    "        cnt+=1\n",
    "    except:\n",
    "        pass       \n",
    "print (\"%d tweets inserted.\"%cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5ac6fc98a313fc0a38a3e47d'),\n",
      " 'created_at': datetime.datetime(2015, 3, 15, 21, 41, 22),\n",
      " 'favorite_count': 0,\n",
      " 'retweet_count': 0,\n",
      " 'tags': ['#Bigdata', '#I…'],\n",
      " 'text': 'RT @MarcWilczek: In 2014, the digital universe equaled 1.7 megabytes '\n",
      "         'a minute for every person on Earth: http://t.co/gLf50KtZKx #Bigdata '\n",
      "         '#I…',\n",
      " 'tweet_id': 577223085054558208,\n",
      " 'urls': ['http://t.co/gLf50KtZKx']}\n",
      "{'_id': ObjectId('5ac6fc98a313fc0a38a3e47e'),\n",
      " 'created_at': datetime.datetime(2015, 3, 15, 21, 41, 30),\n",
      " 'favorite_count': 0,\n",
      " 'retweet_count': 0,\n",
      " 'tags': [],\n",
      " 'text': 'Tanginang database to',\n",
      " 'tweet_id': 577223118327926785,\n",
      " 'urls': []}\n",
      "{'_id': ObjectId('5ac6fc98a313fc0a38a3e47f'),\n",
      " 'created_at': datetime.datetime(2015, 3, 15, 21, 41, 31),\n",
      " 'favorite_count': 0,\n",
      " 'retweet_count': 0,\n",
      " 'tags': ['#AgTech', '#AgBots', '#Robotics', '#Automation', '#Io…'],\n",
      " 'text': 'RT @chrisco: The future of farming: robots + big data: '\n",
      "         'http://t.co/MiEIZmKzEb via @KurzweilAINews #AgTech #AgBots #Robotics '\n",
      "         '#Automation #Io…',\n",
      " 'tweet_id': 577223124862697472,\n",
      " 'urls': ['http://t.co/MiEIZmKzEb']}\n",
      "{'_id': ObjectId('5ac6fc98a313fc0a38a3e480'),\n",
      " 'created_at': datetime.datetime(2015, 3, 15, 21, 41, 40),\n",
      " 'favorite_count': 0,\n",
      " 'retweet_count': 0,\n",
      " 'tags': ['#cloud', '#bigdata', '#aws', '#ec2'],\n",
      " 'text': 'RT @Brian_Singer_: The EMC Federation Joins the OpenStack Foundation '\n",
      "         'http://t.co/i37gbFthQw #cloud #bigdata #aws #ec2 '\n",
      "         'http://t.co/uYQIXOSMHs',\n",
      " 'tweet_id': 577223160195502080,\n",
      " 'urls': ['http://t.co/i37gbFthQw', 'http://t.co/uYQIXOSMHs']}\n",
      "{'_id': ObjectId('5ac6fc98a313fc0a38a3e481'),\n",
      " 'created_at': datetime.datetime(2015, 3, 15, 21, 41, 46),\n",
      " 'favorite_count': 0,\n",
      " 'retweet_count': 0,\n",
      " 'tags': ['#BigData'],\n",
      " 'text': 'RT @execedia: Learn @execedia: The Business Benefits of Big Data '\n",
      "         'http://t.co/uQSGCKEiOn\\n'\n",
      "         ' #BigData',\n",
      " 'tweet_id': 577223187110330368,\n",
      " 'urls': ['http://t.co/uQSGCKEiOn']}\n",
      "{'_id': ObjectId('5ac6fc98a313fc0a38a3e482'),\n",
      " 'created_at': datetime.datetime(2015, 3, 15, 21, 41, 54),\n",
      " 'favorite_count': 0,\n",
      " 'retweet_count': 0,\n",
      " 'tags': ['#bigdata', '#natgeosxsw'],\n",
      " 'text': 'RT @RiverCityGal: The goal is not to keep #bigdata scary but to turn '\n",
      "         'it into something beautiful @kalpenn #natgeosxsw @NatGeoChannel',\n",
      " 'tweet_id': 577223217942691840,\n",
      " 'urls': []}\n",
      "{'_id': ObjectId('5ac6fc98a313fc0a38a3e483'),\n",
      " 'created_at': datetime.datetime(2015, 3, 15, 21, 41, 56),\n",
      " 'favorite_count': 0,\n",
      " 'retweet_count': 0,\n",
      " 'tags': ['#bigdata'],\n",
      " 'text': 'RT @TheHesterView: MT .@techrepublic WhiteHouse + climate change: '\n",
      "         'hackathons, crowdsourcing, #bigdata http://t.co/6HWjCv3BL5 Lets join '\n",
      "         'in! …',\n",
      " 'tweet_id': 577223226444509185,\n",
      " 'urls': ['http://t.co/6HWjCv3BL5']}\n",
      "{'_id': ObjectId('5ac6fc98a313fc0a38a3e484'),\n",
      " 'created_at': datetime.datetime(2015, 3, 15, 21, 41, 58),\n",
      " 'favorite_count': 0,\n",
      " 'retweet_count': 0,\n",
      " 'tags': [],\n",
      " 'text': '@TurnupPrince if there was some sort of list or database? There is a '\n",
      "         \"general rating list, but i don't think it addresses this \"\n",
      "         'specifically',\n",
      " 'tweet_id': 577223237140148224,\n",
      " 'urls': []}\n",
      "{'_id': ObjectId('5ac6fc98a313fc0a38a3e485'),\n",
      " 'created_at': datetime.datetime(2015, 3, 15, 21, 42, 1),\n",
      " 'favorite_count': 0,\n",
      " 'retweet_count': 0,\n",
      " 'tags': ['algorithm'],\n",
      " 'text': 'Can you replace a recruiter with an algorithm? '\n",
      "         'http://t.co/rLNk2UtnkL',\n",
      " 'tweet_id': 577223250566082560,\n",
      " 'urls': ['http://t.co/rLNk2UtnkL']}\n"
     ]
    }
   ],
   "source": [
    "for tweet in db.tweets.find().limit(9):\n",
    "    pprint.pprint(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigdata count 0\n",
      "big data count 1\n",
      "algorithm count 1\n",
      "AI count 0\n",
      "MongoDB count 2\n",
      "SQL count 1\n",
      "artificial intelligence count 0\n",
      "machine learning count 0\n",
      "#Bigdata count 1\n",
      "#I… count 1\n",
      "#AgTech count 1\n",
      "#AgBots count 1\n",
      "#Robotics count 1\n",
      "#Automation count 1\n",
      "#Io… count 1\n",
      "#cloud count 4\n",
      "#bigdata count 14\n",
      "#aws count 3\n",
      "#ec2 count 2\n",
      "#BigData count 13\n",
      "#natgeosxsw count 1\n",
      "#Analytics count 6\n",
      "#amazon count 2\n",
      "#IT count 2\n",
      "#HRtech count 2\n",
      "#HR count 2\n",
      "#People count 2\n",
      "#Cloud count 3\n",
      "#data count 1\n",
      "#DataScientists count 1\n",
      "#Hackathon count 3\n",
      "#BDH count 1\n",
      "#sme count 2\n",
      "#thamesvalley count 2\n",
      "#php count 5\n",
      "#database count 5\n",
      "#IoT count 1\n",
      "#job#SeniorOracleDBA count 1\n",
      "#banktech count 1\n",
      "#fintech count 1\n",
      "#ITJob count 3\n",
      "#Job count 3\n",
      "#Plymouth count 1\n",
      "#hiring count 1\n",
      "#Wilmington count 1\n",
      "#job count 2\n",
      "#Sioux count 1\n",
      "#Wearables count 1\n",
      "#IOT count 1\n",
      "#3DPrinting count 1\n",
      "#Selfie: count 1\n",
      "#Today count 1\n",
      "#Zimbabwe count 1\n",
      "#TeaParty count 1\n",
      "#tcot count 1\n",
      "#PJNet count 1\n"
     ]
    }
   ],
   "source": [
    "for key, value in hashtags.items():\n",
    "    print (\"%s count %d\"%(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_dct(dct,thresh): \n",
    "  tmp={}    \n",
    "  keys=dct.keys()\n",
    "  for key in keys:\n",
    "    if dct[key] > thresh:\n",
    "        tmp[key]=dct[key]\n",
    "  return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor key, value in tags.items():\\n    print (\"%s count %d\"%(key, value))\\n'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for key, value in tags.items():\n",
    "    print (\"%s count %d\"%(key, value))\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=trim_dct(tags,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT count 32\n",
      "database count 6\n",
      "via count 10\n",
      "#bigdata count 14\n",
      "#BigData count 13\n",
      "#Analytics count 6\n",
      "- count 9\n"
     ]
    }
   ],
   "source": [
    "for key, value in tags.items():\n",
    "    print (\"%s count %d\"%(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://t.co/gLf50KtZKx count 1\n",
      "http://t.co/MiEIZmKzEb count 1\n",
      "http://t.co/i37gbFthQw count 1\n",
      "http://t.co/uYQIXOSMHs count 1\n",
      "http://t.co/uQSGCKEiOn count 1\n",
      "http://t.co/6HWjCv3BL5 count 1\n",
      "http://t.co/rLNk2UtnkL count 1\n",
      "http://t.co/92XV9CUUpO count 1\n",
      "http://t.co/fi0MuG9QUH count 1\n",
      "http://t.co/jRLp7… count 1\n",
      "http://t.co/w4xw93Tw19 count 2\n",
      "http://t.co/wdK8JZM7db count 1\n",
      "http://t.co/tkSfjPpods count 1\n",
      "http://t.co/mM0… count 1\n",
      "http… count 1\n",
      "https://t.co/BGmnXAOlIY count 1\n",
      "http:… count 1\n",
      "http://t.co/EBChICLch2 count 1\n",
      "http://t.co/SgcfxbdQvZ count 1\n",
      "http://t.c… count 1\n",
      "http://t.co/Jfh5Xc2hQz count 1\n",
      "http://t.co/SIHVND8mDY count 2\n",
      "http://t.co/… count 2\n",
      "http://t.co/OGcvtI1663 count 1\n",
      "http://t.co/n5kJRoYydW count 1\n",
      "https://t.co/TzrPR5rtY8 count 1\n",
      "http://t.co/UQg7q3EvHp count 1\n",
      "http://t.co/BZN44MeEYF count 2\n",
      "http://t.co/rPVg5Kd7q1 count 1\n",
      "http://t.co/gXAsZVt1IQ count 1\n",
      "http://t.co/Qh5Lkvcyyz count 1\n",
      "http://t.co/d6O7BOcfKQ count 2\n",
      "http://t.co/CUES54iN0m count 1\n",
      "http://t.co/Oq7Dkb4TRy count 1\n",
      "http://t.… count 1\n",
      "http://t.co/2nRzT2B4iH count 1\n",
      "http://t.co/PrsiwzWf5x count 1\n",
      "http://t.co/BSUagSGlOd count 1\n",
      "http://t.co/x564K5OLun count 1\n",
      "http://t.co/5VsZsiRecp count 1\n",
      "http://t.co/FkmBzkP6Zt count 1\n",
      "http://t.co/0cmXLWxKoT count 1\n",
      "http://t.co/k0sIrpiELj count 1\n",
      "http://t.co/2ZLL1YISmx count 1\n",
      "http://t.co/CyGYsMOXVo count 1\n",
      "http://t.co/yE2yhaLqkY count 1\n",
      "http://t.co/9XowKLMwnX count 1\n",
      "http://t.co/CQMbFnRO1r count 1\n",
      "http://t.co/cWslYbhxbk count 1\n",
      "http://t.co/uBXDEMJPQN count 1\n"
     ]
    }
   ],
   "source": [
    "for key, value in urls.items():\n",
    "    print (\"%s count %d\"%(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Updated October 3, 2017"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
